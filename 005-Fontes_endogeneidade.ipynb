{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fontes de Endogeneidade\n",
    "\n",
    "Prof. Daniel de Abreu Pereira Uhr\n",
    "\n",
    "## Conteúdo\n",
    "\n",
    "* Fontes de Endogeneidade\n",
    "  * Omissão de Variáveis Relevantes (Subespecificação) vs Inclusão de Variáveis Irrelevantes (Sobre-especificação)\n",
    "  * Erro de Medida (Measurement Error) - Variável dependente vs Variável independente\n",
    "  * Viés de Simultaneidade (Simultaneity Bias/Reverse Causality)\n",
    "  * Viés de Seleção Amostral (Sample Selection Bias)\n",
    "  * Viés de Seleção pelo Tratamento/Fator de confusão (Treatment Selection Bias/Confounding)\n",
    " \n",
    "\n",
    "## Referências\n",
    "\n",
    "* HAYASHI , F. Econometrics, Princeton university press, 2000.\n",
    "* Greene, W. H. Econometric Analysis. New Jersey. Prentice Hall; 5th edition. (2002).\n",
    "* Gujarati, D. N. Econometria Básica. 5ª ed. Rio de Janeiro: Elsevier, 2011.\n",
    "* Wooldridge, J.M. 2002. Econometric Analysis of Cross Section and Panel Data. Cambridge, MA: MIT Press, pp.282-283.\n",
    "* Wooldridge, J. M. Introdução à Econometria: uma abordagem moderna. São Paulo: Cengage Learning, 2015.\n",
    "* Pereda, P. C., & Alves, D. Econometria Aplicada, Elsevier, 2018.\n",
    "* NOTAS PRÓPRIAS\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fontes de Endogeneidade\n",
    "\n",
    "O desenvolvimento da econometria mostrou que o estimador OLS é sensível a violações das hipóteses fundamentais, especialmente a hipótese de exogeneidade, que requer que o termo de erro não esteja correlacionado com as variáveis explicativas. Quando essa hipótese é violada, ocorre endogeneidade, resultando em estimadores viesados e inconsistentes. É essencial que os pesquisadores identifiquem as possíveis **fontes de endogeneidade** para aplicar as correções necessárias.\n",
    "\n",
    "**Fontes Comuns de Endogeneidade:**\n",
    "\n",
    "- Omissão de Variável Relevante (Subespecificação) vs Inclusão de Variável Irrelevante (Sobre-especificação)\n",
    "- Erro de Medida (Measurement Error) - Variável dependente vs Variável independente\n",
    "- Viés de Simultaneidade (Simultaneity Bias/Reverse Causality)\n",
    "- Viés de Seleção Amostral (Sample Selection Bias)\n",
    "- Viés de Seleção pelo Tratamento/Fator de confusão (Treatment Selection Bias/Confounding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Omissão de Variável Relevante (Subespecificação)\n",
    "\n",
    "Quando uma variável relevante é omitida do modelo de regressão, os estimadores de OLS podem se tornar viesados e inconsistentes, especialmente se a variável omitida estiver correlacionada com as variáveis incluídas no modelo.\n",
    "\n",
    "**Modelo Verdadeiro:**\n",
    "\n",
    "$$ Y_i = \\beta_1 + \\beta_2 X_{i2} + \\beta_3 X_{i3} + u_i $$\n",
    "\n",
    "**Modelo Estimado:**\n",
    "\n",
    "$$ Y_i = \\alpha_1 + \\alpha_2 X_{i2} + u_i $$\n",
    "\n",
    "**Consequências:**\n",
    "- Se a variável $ X_{i3} $ estiver correlacionada com $ X_{i2} $, os coeficientes estimados $ \\hat{\\alpha}_1 $ e $ \\hat{\\alpha}_2 $ serão viesados e inconsistentes.\n",
    "- Se $ X_{i3} $ não estiver correlacionada com $ X_{i2} $, $ \\hat{\\alpha}_2 $ será não viesado, mas a precisão (eficiência) do estimador pode ser comprometida.\n",
    "- A variância dos erros $ \\sigma^2 $ será estimada incorretamente, o que afeta a precisão dos intervalos de confiança e dos testes de hipóteses.\n",
    "\n",
    "**Exemplo Prático:**\n",
    "Suponha que você esteja modelando o salário com base na educação ($ X_{i2} $), mas omite a experiência ($ X_{i3} $). Se a experiência estiver correlacionada com a educação, o efeito da educação sobre o salário será superestimado, pois parte do efeito da experiência será indevidamente atribuído à educação.\n",
    "\n",
    "**Correção:**\n",
    "Adicionar a variável relevante ao modelo ou usar variáveis instrumentais (IV) para lidar com a endogeneidade.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inclusão de Variável Irrelevante (Sobre-especificação)\n",
    "\n",
    "Quando uma variável irrelevante é incluída no modelo, os estimadores de OLS permanecem não viesados e consistentes, mas podem se tornar menos eficientes.\n",
    "\n",
    "**Modelo Verdadeiro:**\n",
    "\n",
    "$$ Y_i = \\beta_1 + \\beta_2 X_{i2} + u_i $$\n",
    "\n",
    "**Modelo Estimado:**\n",
    "\n",
    "$$ Y_i = \\alpha_1 + \\alpha_2 X_{i2} + \\alpha_3 X_{i3} + u_i $$\n",
    "\n",
    "**Consequências:**\n",
    "- Os estimadores de OLS permanecem não viesados: $ E(\\hat{\\alpha}_1) = \\beta_1 $, $ E(\\hat{\\alpha}_2) = \\beta_2 $, e $ E(\\hat{\\alpha}_3) = 0 $.\n",
    "- A inclusão de $ X_{i3} $ aumenta a variância de $ \\hat{\\alpha}_2 $, tornando-o menos preciso.\n",
    "- Embora os intervalos de confiança e os testes de hipóteses permaneçam válidos, a eficiência do estimador é comprometida.\n",
    "\n",
    "**Correção:**\n",
    "Testes de especificação, como o *Teste de Ramsey RESET*, podem ser utilizados para identificar sobre-especificação e ajustar o modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simulação em Python:**\n",
    "\n",
    "Vamos fazer uma simulação para ilustrar a diferença entre subespecificação e sobre-especificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X_irrelevant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>213.268785</td>\n",
       "      <td>50.469604</td>\n",
       "      <td>44.238499</td>\n",
       "      <td>-0.037385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>296.321458</td>\n",
       "      <td>67.409272</td>\n",
       "      <td>60.516168</td>\n",
       "      <td>-0.859806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>178.457490</td>\n",
       "      <td>41.156650</td>\n",
       "      <td>39.455693</td>\n",
       "      <td>-0.400883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>196.730583</td>\n",
       "      <td>50.797561</td>\n",
       "      <td>41.562741</td>\n",
       "      <td>2.271544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>214.198501</td>\n",
       "      <td>54.519659</td>\n",
       "      <td>46.933682</td>\n",
       "      <td>0.600924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Y         X2         X3  X_irrelevant\n",
       "0  213.268785  50.469604  44.238499     -0.037385\n",
       "1  296.321458  67.409272  60.516168     -0.859806\n",
       "2  178.457490  41.156650  39.455693     -0.400883\n",
       "3  196.730583  50.797561  41.562741      2.271544\n",
       "4  214.198501  54.519659  46.933682      0.600924"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Semente para reprodução de resultados\n",
    "np.random.seed(1515)\n",
    "\n",
    "# Numero de observações\n",
    "n = 1000\n",
    "\n",
    "# Coeficientes\n",
    "beta_1 = 2.0\n",
    "beta_2 = 1.5\n",
    "beta_3 = 3.0\n",
    "\n",
    "# Gerando dados aleatórios para X2 e X3\n",
    "X2 = np.random.normal(50, 10, n)  # Education, for example\n",
    "X3 = 0.8 * X2 + np.random.normal(5, 2, n)  # Experience, with higher correlation with Education\n",
    "\n",
    "# Termo de Erro\n",
    "u = np.random.normal(0, 5, n)\n",
    "\n",
    "# Modelo verdadeiro\n",
    "Y = beta_1 + beta_2 * X2 + beta_3 * X3 + u\n",
    "\n",
    "# Criação de uma variável irrelevante \n",
    "X_irrelevant = np.random.normal(0, 1, n)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Y': Y,\n",
    "    'X2': X2,\n",
    "    'X3': X3,\n",
    "    'X_irrelevant': X_irrelevant\n",
    "})\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Omissão de Variável Relevante (Subespecificação)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.964\n",
      "Model:                            OLS   Adj. R-squared:                  0.964\n",
      "Method:                 Least Squares   F-statistic:                 2.646e+04\n",
      "Date:                Thu, 15 Aug 2024   Prob (F-statistic):               0.00\n",
      "Time:                        17:47:08   Log-Likelihood:                -3466.5\n",
      "No. Observations:                1000   AIC:                             6937.\n",
      "Df Residuals:                     998   BIC:                             6947.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     17.9483      1.243     14.438      0.000      15.509      20.388\n",
      "X2             3.8895      0.024    162.668      0.000       3.843       3.936\n",
      "==============================================================================\n",
      "Omnibus:                        1.542   Durbin-Watson:                   1.805\n",
      "Prob(Omnibus):                  0.463   Jarque-Bera (JB):                1.485\n",
      "Skew:                           0.012   Prob(JB):                        0.476\n",
      "Kurtosis:                       2.813   Cond. No.                         264.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "reg1 = smf.ols('Y ~ X2', data=df).fit()\n",
    "print(reg1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo verdadeiro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.986\n",
      "Model:                            OLS   Adj. R-squared:                  0.986\n",
      "Method:                 Least Squares   F-statistic:                 3.578e+04\n",
      "Date:                Thu, 15 Aug 2024   Prob (F-statistic):               0.00\n",
      "Time:                        17:47:09   Log-Likelihood:                -2980.2\n",
      "No. Observations:                1000   AIC:                             5966.\n",
      "Df Residuals:                     997   BIC:                             5981.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      2.1976      0.858      2.561      0.011       0.514       3.881\n",
      "X2             1.4390      0.062     23.107      0.000       1.317       1.561\n",
      "X3             3.0664      0.076     40.495      0.000       2.918       3.215\n",
      "==============================================================================\n",
      "Omnibus:                        0.767   Durbin-Watson:                   1.931\n",
      "Prob(Omnibus):                  0.681   Jarque-Bera (JB):                0.700\n",
      "Skew:                          -0.063   Prob(JB):                        0.705\n",
      "Kurtosis:                       3.031   Cond. No.                         397.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "reg2 = smf.ols('Y ~ X2 + X3', data=df).fit()\n",
    "print(reg2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inclusão de Variável Irrelevante (Sobre-especificação)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.986\n",
      "Model:                            OLS   Adj. R-squared:                  0.986\n",
      "Method:                 Least Squares   F-statistic:                 2.385e+04\n",
      "Date:                Thu, 15 Aug 2024   Prob (F-statistic):               0.00\n",
      "Time:                        17:47:11   Log-Likelihood:                -2979.7\n",
      "No. Observations:                1000   AIC:                             5967.\n",
      "Df Residuals:                     996   BIC:                             5987.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "Intercept        2.1630      0.859      2.519      0.012       0.478       3.848\n",
      "X2               1.4349      0.062     22.987      0.000       1.312       1.557\n",
      "X3               3.0717      0.076     40.460      0.000       2.923       3.221\n",
      "X_irrelevant     0.1462      0.151      0.969      0.333      -0.150       0.442\n",
      "==============================================================================\n",
      "Omnibus:                        0.674   Durbin-Watson:                   1.927\n",
      "Prob(Omnibus):                  0.714   Jarque-Bera (JB):                0.615\n",
      "Skew:                          -0.059   Prob(JB):                        0.735\n",
      "Kurtosis:                       3.027   Cond. No.                         398.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "reg3 = smf.ols('Y ~ X2 + X3 + X_irrelevant', data=df).fit()\n",
    "print(reg3.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erro de Medida (Measurement Error)\n",
    "\n",
    "Erros de medida podem ocorrer tanto na variável dependente quanto na variável independente, e suas consequências diferem significativamente.\n",
    "\n",
    "#### Erro de Medida na Variável Dependente\n",
    "\n",
    "Quando há um erro de medida na variável dependente, o modelo original é:\n",
    "\n",
    "$$ Y_{i}^{*} = \\alpha + \\beta X_{i} + u_{i} $$\n",
    "\n",
    "Aqui, $ Y_{i}^{*} $ é a variável dependente verdadeira, mas o que observamos é $ Y_i $ que contém um erro de medida $ e_i $:\n",
    "\n",
    "$$ Y_{i} = Y_{i}^{*} + e_{i} $$\n",
    "\n",
    "Substituindo $ Y_{i}^{*} $ na equação do modelo:\n",
    "\n",
    "$$ Y_{i} = (\\alpha + \\beta X_{i} + u_{i}) + e_{i} $$\n",
    "\n",
    "Ou seja:\n",
    "\n",
    "$$ Y_{i} = \\alpha + \\beta X_{i} + (u_{i} + e_{i}) $$\n",
    "\n",
    "Aqui, $ u_i + e_i$ é o termo de erro composto, que incorpora o erro de medida na variável dependente. \n",
    "\n",
    "**Consequências:**\n",
    "\n",
    "- O termo $ e_i $ é simplesmente adicionado ao termo de erro original $ u_i $, o que aumenta a variância total do erro.\n",
    "- Como resultado, o estimador $ \\hat{\\beta} $ do OLS continua sendo **não viesado** e **consistente**, mas a **variância** do estimador aumenta.\n",
    "\n",
    "A variância do estimador $ \\hat{\\beta} $ é dada por:\n",
    "\n",
    "$$ \\text{V}(\\hat{\\beta}) = \\frac{\\sigma_u^2}{V(X)} $$\n",
    "\n",
    "Com o erro de medida $ e_i $, a variância do termo de erro total $ v_i = u_i + e_i $ se torna $ \\sigma_v^2 = \\sigma_u^2 + \\sigma_e^2 $. Portanto, a variância do estimador $ \\hat{\\beta} $ com erro de medida é:\n",
    "\n",
    "$$ \\text{V}(\\hat{\\beta}) = \\frac{\\sigma_u^2 + \\sigma_e^2}{V(X)} $$\n",
    "\n",
    "**Conclusão:** O erro de medida na variável dependente aumenta a variância do estimador $ \\hat{\\beta} $, tornando-o menos eficiente. Isso prejudica a precisão dos intervalos de confiança e a potência dos testes de hipóteses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Erro de Medida na Variável Independente:**\n",
    "\n",
    "- O estimador OLS se torna viesado e inconsistente, resultando em estimativas errôneas dos coeficientes.\n",
    "\n",
    "**Modelo Verdadeiro:**\n",
    "\n",
    "$$ Y_i = \\alpha + \\beta X_i + u_i $$\n",
    "\n",
    "**Variável com Erro de Medida:**\n",
    "\n",
    "$$ X_i^* = X_i + w_i $$\n",
    "\n",
    "Aqui, $ X_i^* $ é a variável observada com erro de medida, onde $ w_i $ é o erro de medida.\n",
    "\n",
    "**Substituição no Modelo:**\n",
    "\n",
    "Se substituirmos $ X_i = X_i^* - w_i $ no modelo verdadeiro, temos:\n",
    "\n",
    "$$ Y_i = \\alpha + \\beta (X_i^* - w_i) + u_i $$\n",
    "\n",
    "$$ Y_i = \\alpha + \\beta X_i^* - \\beta w_i + u_i $$\n",
    "\n",
    "Vamos chamar esse termo $ z_i = u_i - \\beta w_i $. Assim, o modelo se torna:\n",
    "\n",
    "$$ Y_i = \\alpha + \\beta X_i^* + z_i $$\n",
    "\n",
    "**Covariância:**\n",
    "\n",
    "Agora, calculamos a covariância entre $ z_i $ e $X_i^* $:\n",
    "\n",
    "$$ \\text{Cov}[z_i, X_i^*] = E\\left[ (z_i - E(z_i)) \\cdot (X_i^* - E(X_i^*)) \\right] $$\n",
    "\n",
    "Substituindo $ z_i = u_i - \\beta w_i $ e $ X_i^* = X_i + w_i $:\n",
    "\n",
    "$$ = E\\left[ ((u_i - \\beta w_i) - E(u_i - \\beta w_i)) \\cdot (X_i^* - E(X_i^*)) \\right] $$\n",
    "$$ = E\\left[ (u_i - \\beta w_i) \\cdot (X_i + w_i - E(X_i + w_i)) \\right] $$\n",
    "\n",
    "Simplificando, dado que $ E(u_i) = 0$, $ E(w_i) = 0 $, e $ X_i^* $ é a variável observada:\n",
    "\n",
    "$$ = E\\left[ (u_i - \\beta w_i) \\cdot w_i \\right] $$\n",
    "$$ = E\\left[ u_i \\cdot w_i - \\beta w_i^2 \\right] $$\n",
    "\n",
    "Assumindo que $ u_i $ e $ w_i $ são não correlacionados, $ E[u_i \\cdot w_i] = 0 $:\n",
    "\n",
    "$$ = E\\left[ -\\beta w_i^2 \\right] $$\n",
    "$$ = -\\beta E[w_i^2] $$\n",
    "$$ = -\\beta \\sigma_{w_i}^2 $$\n",
    "\n",
    "Portanto, a covariância entre $ z_i $ e $ X_i^* $ é $ -\\beta \\sigma_{w_i}^2 $, que não é zero. \n",
    "\n",
    "Isso significa que a variável explicativa $ X_i^*$ e o termo de erro $ z_i $ são correlacionados, **violando a hipótese de exogeneidade estrita**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simulação em Python:**\n",
    "\n",
    "Vamos realizar uma simulação para ilustrar o impacto do erro de medida na variável dependente e independente. Vamos criar as variáveis \"observadas\" (observed), tanto para dependente quanto para independente, e comparar os resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando os erros de medida para cada variável. Os erros são distribuídos normalmente com média 0 e desvio padrão 5\n",
    "measurement_error_Y = np.random.normal(0, 5, len(df))\n",
    "measurement_error_X2 = np.random.normal(0, 5, len(df))\n",
    "\n",
    "# Adicionando as variáveis com erro de medida ao dataframe\n",
    "df['Y_observed'] = df['Y'] + measurement_error_Y\n",
    "df['X2_observed'] = df['X2'] + measurement_error_X2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos considerar o modelo verdadeiro, e rodar a regressão para a variável dependente observada e verificar os resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             Y_observed   R-squared:                       0.971\n",
      "Model:                            OLS   Adj. R-squared:                  0.971\n",
      "Method:                 Least Squares   F-statistic:                 1.672e+04\n",
      "Date:                Thu, 15 Aug 2024   Prob (F-statistic):               0.00\n",
      "Time:                        18:26:33   Log-Likelihood:                -3359.2\n",
      "No. Observations:                1000   AIC:                             6724.\n",
      "Df Residuals:                     997   BIC:                             6739.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      2.5941      1.253      2.070      0.039       0.134       5.054\n",
      "X2             1.4299      0.091     15.718      0.000       1.251       1.608\n",
      "X3             3.0706      0.111     27.758      0.000       2.854       3.288\n",
      "==============================================================================\n",
      "Omnibus:                        0.496   Durbin-Watson:                   1.929\n",
      "Prob(Omnibus):                  0.780   Jarque-Bera (JB):                0.549\n",
      "Skew:                           0.051   Prob(JB):                        0.760\n",
      "Kurtosis:                       2.947   Cond. No.                         397.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Modelo1: Erro de medida em Y\n",
    "model_1 = smf.ols('Y_observed ~ X2 + X3', data=df).fit()\n",
    "print(model_1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "é possivel verificar que a variância dos coeficientes é maior quando há erro de medida na variável dependente (e as estatísticas t reduziram), mas os coeficientes são consistentes.\n",
    "\n",
    "Agora vamos utilizar a variável independente com erro de medida e verificar os resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.981\n",
      "Model:                            OLS   Adj. R-squared:                  0.981\n",
      "Method:                 Least Squares   F-statistic:                 2.541e+04\n",
      "Date:                Thu, 15 Aug 2024   Prob (F-statistic):               0.00\n",
      "Time:                        18:27:14   Log-Likelihood:                -3148.6\n",
      "No. Observations:                1000   AIC:                             6303.\n",
      "Df Residuals:                     997   BIC:                             6318.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "Intercept      -0.9160      0.999     -0.917      0.360      -2.877       1.045\n",
      "X2_observed     0.3269      0.033      9.811      0.000       0.262       0.392\n",
      "X3              4.3695      0.046     95.662      0.000       4.280       4.459\n",
      "==============================================================================\n",
      "Omnibus:                        0.061   Durbin-Watson:                   1.958\n",
      "Prob(Omnibus):                  0.970   Jarque-Bera (JB):                0.032\n",
      "Skew:                          -0.013   Prob(JB):                        0.984\n",
      "Kurtosis:                       3.010   Cond. No.                         392.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Modelo 3: Erro de medida em X2\n",
    "model_2 = smf.ols('Y ~ X2_observed + X3', data=df).fit()\n",
    "print(model_2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repare que os coeficientes estimados são viesados e inconsistentes, pois a variável explicativa e o termo de erro estão correlacionados (Há endogeneidade). \n",
    "\n",
    "O coeficiente estimado para a variável independente \"X2_observed\" é menor que o valor verdadeiro, mostrando o viés negativo. O viés negativo de um coeficiente estimado ocorre quando o valor esperado do coeficiente estimado é menor que o valor verdadeiro do coeficiente. Isso significa que, em média, o estimador tende a subestimar o verdadeiro valor do coeficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viés de Simultaneidade (Simultaneity Bias/Reverse Causality)\n",
    "\n",
    "O viés de simultaneidade ocorre quando uma ou mais variáveis explicativas em um modelo de regressão são simultaneamente determinadas com a variável dependente. Isso significa que existe uma causalidade reversa, onde a variável explicativa influencia a variável dependente e, ao mesmo tempo, é influenciada por ela. Em termos mais formais, isso cria uma correlação entre as variáveis independentes e o termo de erro, violando a hipótese de exogeneidade estrita necessária para que o estimador OLS seja consistente.\n",
    "\n",
    "Considere um modelo simples de oferta e demanda para um bem, onde a quantidade $ Q $ e o preço $ P $ são determinadas simultaneamente:\n",
    "\n",
    "- Função de Demanda:\n",
    "  $$\n",
    "  Q_d = \\alpha - \\beta P + u_d\n",
    "  $$\n",
    "- Função de Oferta:\n",
    "  $$\n",
    "  Q_s = \\gamma + \\delta P + u_s\n",
    "  $$\n",
    "\n",
    "O equilíbrio de mercado ocorre onde a quantidade demandada é igual à quantidade ofertada:\n",
    "\n",
    "$$\n",
    "Q_d = Q_s\n",
    "$$\n",
    "\n",
    "Portanto, a variável preço $ P $ está simultaneamente determinada com a quantidade $ Q $. Se tentarmos estimar uma regressão simples de $ Q $ sobre $ P $ usando OLS, obteremos estimadores viesados, pois o preço $ P $ está correlacionado com o termo de erro, que agora incorpora os choques tanto na oferta quanto na demanda.\n",
    "\n",
    "Como consequencias, temos:\n",
    "- O estimador OLS será inconsistente, o que significa que, mesmo com um grande tamanho de amostra, o estimador não convergirá para o verdadeiro valor do parâmetro.\n",
    "- As inferências feitas a partir do modelo serão incorretas, resultando em conclusões potencialmente errôneas sobre as relações causais entre as variáveis.\n",
    "\n",
    "**Exemplo**\n",
    "\n",
    "No contexto da economia, considere o modelo de oferta e demanda. Se estimarmos a relação entre preço e quantidade usando apenas uma regressão OLS, ignorando a simultaneidade, poderíamos subestimar ou superestimar a elasticidade-preço da demanda ou oferta.\n",
    "\n",
    "**Correção**\n",
    "\n",
    "Uma abordagem comum para corrigir o viés de simultaneidade é o uso de **Variáveis Instrumentais (IV)**. A ideia é encontrar uma variável que esteja correlacionada com a variável explicativa endógena, mas que não esteja correlacionada com o termo de erro. Caso exista mais de uma variável exógena excluída correlacionada com a variável endógena, utilizamos o **Mínimos Quadrados em Dois Estágios (2SLS)**, onde no primeiro estágio a variável endógena é projetada sobre as variáveis exógenas e no segundo estágio essa projeção é usada para estimar o modelo de interesse.\n",
    "\n",
    "\n",
    "### Viés de Seleção Amostral (Sample Selection Bias)\n",
    "\n",
    "O viés de seleção amostral ocorre quando a amostra utilizada em uma análise não é representativa da população alvo devido a um processo de seleção que está correlacionado com a variável dependente. Isso resulta em estimadores viesados e inconsistentes, pois a amostra não reflete adequadamente a variação e as relações presentes na população como um todo. Em outras palavras, a amostra não é aleatória, mas sim \"selecionada\" de uma maneira que distorce as relações entre as variáveis.\n",
    "\n",
    "O viés de seleção amostral pode surgir de várias formas, incluindo, por exemplo: (i) viés de não-resposta, onde os não-respondentes diferem dos respondentes; (ii) viés de atrito, onde os indivíduos que saem da amostra diferem dos que permanecem; (iii) viés de seleção de amostragem, onde a amostra é selecionada de forma não aleatória.\n",
    "\n",
    "\n",
    "**Modelo com Viés de Seleção Amostral:**\n",
    "\n",
    "Considere um modelo onde estamos interessados em estimar o impacto da educação sobre o salário:\n",
    "\n",
    "$$\n",
    "\\text{Salário}_i = \\alpha + \\beta \\text{Educação}_i + u_i\n",
    "$$\n",
    "\n",
    "Se a amostra incluir *apenas indivíduos empregados*, podemos estar ignorando os indivíduos desempregados, que poderiam ter características (observáveis ou não observáveis) que afetam tanto a probabilidade de emprego quanto o salário. Isso introduz o viés de seleção amostral. A mostra não é aleatória, mas sim \"selecionada\" de uma maneira que distorce as relações entre as variáveis.\n",
    "\n",
    "Como consequencias, temos:\n",
    "- O estimador OLS aplicado a essa amostra não representativa será viesado, pois a correlação entre o erro $ u_i $ e a variável independente $ \\text{Educação}_i $ não é zero, devido ao processo de seleção.\n",
    "- A interpretação dos coeficientes estimados será inválida, pois eles não se aplicam à população como um todo, mas apenas ao subconjunto da amostra selecionada.\n",
    "\n",
    "**Exemplo**\n",
    "Um exemplo clássico de viés de seleção amostral é o \"viés de busca de emprego\", onde os salários são estimados apenas para os trabalhadores empregados, ignorando os desempregados. Isso pode levar a uma superestimação do salário médio, uma vez que os desempregados podem ter salários mais baixos.\n",
    "\n",
    "**Correção:**\n",
    "Uma abordagem classica para corrigir o viés de seleção amostral é o uso do **Modelo de Seleção de Heckman** (ou correção de Heckman). \n",
    "\n",
    "\n",
    "### Viés de Seleção pelo Tratamento/Fator de confusão (Treatment Selection Bias/Confounding)\n",
    "\n",
    "O viés de seleção pelo tratamento ocorre quando a seleção dos indivíduos para um tratamento (ou intervenção) não é aleatória, mas sim baseada em características observáveis ou não observáveis que também influenciam o resultado de interesse. Esse viés resulta em estimativas que não podem ser interpretadas como efeitos causais do tratamento, uma vez que a comparação entre grupos tratados e não tratados não reflete um cenário contrafactual adequado.\n",
    "\n",
    "Esse viés é comum em estudos observacionais, onde os indivíduos se auto-selecionam para participar de um tratamento com base em suas características, que podem estar correlacionadas com o resultado de interesse. Isso cria um problema de **fator de confusão**, onde a variável de tratamento está correlacionada com outras variáveis que afetam o resultado, tornando difícil isolar o efeito causal do tratamento.\n",
    "\n",
    "Esse viés não depende da coleta de dados, mas sim da forma como os indivíduos são selecionados para o tratamento. Se a seleção para o tratamento é baseada em características que afetam o resultado, o efeito do tratamento será superestimado ou subestimado. É algo que deve considerar os mecanismos econômicos e comportamentais que levam à seleção dos indivíduos para o tratamento.\n",
    "\n",
    "Considere um modelo onde estamos interessados em estimar o impacto de um programa de treinamento sobre o salário:\n",
    "\n",
    "$$\n",
    "\\text{Salário}_i = \\alpha + \\beta \\text{Treinamento}_i + u_i\n",
    "$$\n",
    "\n",
    "Se os indivíduos que participam do treinamento são aqueles mais motivados ou com mais habilidades (fatores não observáveis), isso criará um viés na estimativa de $ \\beta $, pois o treinamento pode estar capturando o efeito dessas características e não o efeito causal do programa.\n",
    "\n",
    "\n",
    "$$\n",
    "\\text{Salário}_i = \\alpha + \\beta \\text{Treinamento}_i + (\\text{Motivação}_i + \\epsilon_i)\n",
    "$$\n",
    "\n",
    "Como consequencias, temos:\n",
    "- O estimador OLS pode fornecer uma estimativa viesada e inconsistente do impacto do tratamento, porque não controla adequadamente para as diferenças entre os grupos tratados e não tratados.\n",
    "- As conclusões sobre a eficácia do tratamento podem ser enganosas, uma vez que não refletem o verdadeiro efeito causal.\n",
    "\n",
    "**Exemplo**\n",
    "Em um estudo que avalia o impacto de um programa de treinamento no emprego, se apenas aqueles que já têm uma maior propensão a conseguir emprego (por exemplo, por terem mais experiência) participarem do programa, o impacto do treinamento será superestimado.\n",
    "\n",
    "**Correção:**\n",
    "Existem várias abordagens para corrigir o viés de seleção pelo tratamento, por exemplo, Propensity Score Matching (PSM), Diferenças em Diferenças (DiD), Variáveis Instrumentais (IV).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considerações\n",
    "\n",
    "Vimos que as fontes de viés provocam estimativas inconsistentes e viesadas, comprometendo a validade das inferências feitas a partir dos modelos de regressão. É fundamental que os pesquisadores estejam cientes dessas fontes de endogeneidade e apliquem as correções apropriadas para garantir que os resultados sejam confiáveis e robustos. Em economia, a identificação e correção de endogeneidade são questões centrais para a validade dos resultados empíricos e a formulação de políticas públicas eficazes."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
