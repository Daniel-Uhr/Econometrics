{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M√≠nimos Quadrados Ordin√°rios (MQO / Ordinary Least Squares - OLS)\n",
    "\n",
    "Prof. Daniel de Abreu Pereira Uhr\n",
    "\n",
    "### Conte√∫do\n",
    "\n",
    "* Estimador de M√≠nimos Quadrados Ordin√°rios (MQO, ou *Ordinary Least Squares - OLS*)\n",
    "  * Hip√≥teses do MQO:\n",
    "    * Linearidade\n",
    "    * Exogeneidade estrita\n",
    "    * N√£o-Multicolineariade\n",
    "    * Vari√¢ncia esf√©rica do erro\n",
    "    * Erro √© normalmente distribu√≠do\n",
    "  * √Ålgebra do Estimador OLS\n",
    "  * **Propriedades do Estimador OLS**\n",
    "  * N√£o-vies\n",
    "  * Consist√™ncia\n",
    "  * Efici√™ncia\n",
    "  * Normalidade\n",
    "  \n",
    "* Infer√™ncia com OLS\n",
    "  * Teste-T, IC, e p-valor\n",
    "  * $R^{2}$ e $R^{2}$ ajustado\n",
    "  * Outras M√©tricas para Avaliar o Desempenho da Regress√£o\n",
    "  * Teste F\n",
    "\n",
    "* Exemplos de Infer√™ncia e Regress√£o no Python\n",
    "  \n",
    "\n",
    "### Refer√™ncias\n",
    "\n",
    "* HAYASHI , F. Econometrics, Princeton university press, 2000.\n",
    "* Gujarati, D. N. Econometria B√°sica. 5¬™ ed. Rio de Janeiro: Elsevier, 2011.\n",
    "* Wooldridge, J. M. Introdu√ß√£o √† Econometria: uma abordagem moderna. S√£o Paulo: Cengage Learning, 2015.\n",
    "* Pereda, P. C., & Alves, D. Econometria Aplicada, Elsevier, 2018.\n",
    "* Cattaneo (2010) Journal of Econometrics 155: 138‚Äì154\n",
    "* NOTAS PR√ìPRIAS\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimador de M√≠nimos Quadrados Ordin√°rios (MQO, ou *Ordinary Least Squares - OLS*).\n",
    "\n",
    "A regress√£o populacional √© a forma te√≥rica da rela√ß√£o entre a vari√°vel dependente $Y_{i}$ e as vari√°veis independentes $X_{i}$ com base na popula√ß√£o inteira. Onde, $\\beta$ representa os verdadeiros par√¢metros desconhecidos e $u_{i}$ √© o termo de erro ou dist√∫rbio, que captura todos os fatores que influenciam $Y_{i}$ al√©m de $X_{i}$. \n",
    "\n",
    "$$\n",
    "Y_{i} = \\beta_{1}X_{i1} + \\beta_{2}X_{i2} + ... + \\beta_{k}X_{ik} + u_{i}\n",
    "$$\n",
    "\n",
    "Para avan√ßar no prop√≥sito de identifica√ß√£o desses par√¢metros o pesquisador utilizar√°, al√©m de uma amostra, o m√©todo de M√≠nimos Quadrados Ordin√°rios (*Ordinary Least Squares - OLS*). \n",
    "\n",
    "### Hip√≥teses do OLS\n",
    "\n",
    "O modelo cl√°ssico OLS de regress√£o linear satisfaz as seguintes hip√≥teses (Hayashi, 2000):\n",
    "\n",
    "* 1. Linearidade\n",
    "* 2. Exogeneidade estrita\n",
    "* 3. N√£o-Multicolineariade\n",
    "* 4. Vari√¢ncia esf√©rica do erro.\n",
    "* 5. Erro √© normalmente distribu√≠do\n",
    "\n",
    "Vejamos por partes. A **hip√≥tese 1** define que a rela√ß√£o entre a vari√°vel dependente ($y$) e as vari√°veis independentes ($x$) √© linear. \n",
    "\n",
    "$$\n",
    "y_{i} = \\beta_{1}x_{i1} + \\beta_{2}x_{i2} + ... + \\beta_{k}x_{ik} + \\epsilon_{i}\n",
    "$$\n",
    "\n",
    "Para $i = 1, 2, ..., n$, onde $n$ √© o n√∫mero de observa√ß√µes. Os coeficientes ($\\beta$) s√£o os par√¢metros do modelo a serem estimados e o termo de erro ($\\epsilon$) √© a parte n√£o observada do modelo.\n",
    "\n",
    "O lado direito da igualdade √© chamado de **fun√ß√£o de regress√£o**, e os coeficientes s√£o chamados de **coeficientes de regress√£o**. A hip√≥tese 1 define que a fun√ß√£o de regress√£o √© linear nos par√¢metros, n√£o nas vari√°veis.\n",
    "\n",
    "**Nota√ß√£o Matricial**\n",
    "\n",
    "Defina vetores K-dimensionais $x_{i}$ e $\\beta$ como:\n",
    "\n",
    "$$\n",
    "x_{i} = \\begin{bmatrix} x_{i1} \\\\ x_{i2} \\\\ \\vdots \\\\ x_{ik} \\end{bmatrix} \\quad \\beta = \\begin{bmatrix} \\beta_{1} \\\\ \\beta_{2} \\\\ \\vdots \\\\ \\beta_{k} \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Pela defini√ß√£o de produto interno de vetores, $x_{i}^{'}\\beta = \\beta_{1}x_{i1} + \\beta_{2}x_{i2} + ... + \\beta_{k}x_{ik}$. Assim, a fun√ß√£o de regress√£o pode ser escrita como:\n",
    "\n",
    "$$\n",
    "y_{i} = x_{i}^{'}\\beta + \\epsilon_{i}\n",
    "$$\n",
    "\n",
    "Defina,\n",
    "\n",
    "$$\n",
    "y=\\begin{bmatrix} y_{1} \\\\ y_{2} \\\\ \\vdots \\\\ y_{n} \\end{bmatrix} \\quad X=\\begin{bmatrix} x_{1}^{'} \\\\ x_{2}^{'} \\\\ \\vdots \\\\ x_{n}^{'} \\end{bmatrix} =  \\begin{bmatrix}\n",
    "x_{11} & ... & x_{1K} \\\\\n",
    "\\vdots & ... & \\vdots \\\\\n",
    "x_{n1} & ... &  x_{nk} \\\\\n",
    "\\end{bmatrix}  \\quad \\epsilon=\\begin{bmatrix} \\epsilon_{1} \\\\ \\epsilon_{2} \\\\ \\vdots \\\\ \\epsilon_{n} \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Assim, a hip√≥tese 1 pode ser escrita como:\n",
    "\n",
    "$$\n",
    "y=X\\beta + \\epsilon\n",
    "$$\n",
    "\n",
    "**Hip√≥tese 2**\n",
    "\n",
    "A exogeneidade estrita √© definida como:\n",
    "\n",
    "$$\n",
    "E(\\epsilon_{i}|X)= E(\\epsilon_{i}|x_{i1}, x_{i2}, ..., x_{ik}) = 0\n",
    "$$\n",
    "\n",
    "A expectativa condicional do termo de erro √© zero, dado os valores das vari√°veis independentes. A hip√≥tese 2 define que as vari√°veis independentes s√£o n√£o correlacionadas com o termo de erro ($\\epsilon$) para todas as condi√ß√µes.\n",
    "\n",
    "Uma implica√ß√£o direta da exogeneidade estrita √© que a expectativa incondicional do termo de erro √© zero:\n",
    "\n",
    "$$\n",
    "E(\\epsilon_{i}) = 0\n",
    "$$\n",
    "Isso ocorre pela lei das expectativas iteradas:\n",
    "\n",
    "$$\n",
    "E(\\epsilon_{i}) = E[E(\\epsilon_{i}|x_{i1}, x_{i2}, ..., x_{ik})] = E[0] = 0\n",
    "$$\n",
    "\n",
    "Al√©m disso, se a covari√¢ncia entre duas vari√°veis aleat√≥rias √© zero, ent√£o dizemos que elas s√£o ortogonais. Sob exogeneidade estrita, as vari√°veis independentes s√£o ortogonais ao termo de erro.\n",
    "\n",
    "$$\n",
    "E(x_{jk}\\epsilon_{i}) = 0\n",
    "$$\n",
    "\n",
    "ou\n",
    "\n",
    "$$\n",
    "E(x_{j}\\epsilon_{i}) = \\begin{bmatrix} E(x_{j1}\\epsilon_{i}) \\\\ E(x_{j2}\\epsilon_{i}) \\\\ \\vdots \\\\ E(x_{jk}\\epsilon_{i}) \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\\\ \\vdots \\\\ 0 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Para relembrar o conceito **expectativa condicional** e de **exogeneidade estrita**. Considere a tabela e responda as quest√µes abaixo.\n",
    "\n",
    "| Y | X | u |\n",
    "|---|---|---|\n",
    "| 4 | 1 | 3 |\n",
    "| 3 | 1 | 2 |\n",
    "| 3 | 1 | 1 |\n",
    "| 1 | 0 | -1 |\n",
    "| 2 | 0 | -2 |\n",
    "| 0 | 0 | -3 |\n",
    "\n",
    "**Calcule:**\n",
    "* E(Y)\n",
    "* E(Y|X=1) e E(Y|X=0)\n",
    "* E(Y|X=1) - E(Y|X=0)\n",
    "* E(u)\n",
    "* Podemos confiar numa regress√£o de Y em X?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M√©dia de Y (E(Y|X=1)):  3.3333333333333335\n",
      "M√©dia de Y (E(Y|X=0)):  1.0\n",
      "(E(Y|X=1)- E(Y|X=0)):  2.3333333333333335\n",
      "M√©dia de u:  0.0\n"
     ]
    }
   ],
   "source": [
    "# NumPy √© uma biblioteca em Python para computa√ß√£o num√©rica e opera√ß√µes matem√°ticas\n",
    "import numpy as np\n",
    "\n",
    "# Dados\n",
    "Y = np.array([4, 3, 3, 1, 2, 0])\n",
    "X = np.array([1, 1, 1, 0, 0, 0])\n",
    "u = np.array([3, 2, 1, -1, -2, -3])\n",
    "\n",
    "# Calcular as m√©dias\n",
    "media_Y = np.mean(Y)\n",
    "media_X = np.mean(X)\n",
    "media_Y_X_1 = np.mean(Y[X == 1])\n",
    "media_Y_X_0 = np.mean(Y[X == 0])\n",
    "dif_media_Y_X = media_Y_X_1 - media_Y_X_0\n",
    "media_u = np.mean(u)\n",
    "\n",
    "print(\"M√©dia de Y (E(Y|X=1)): \", media_Y_X_1)\n",
    "print(\"M√©dia de Y (E(Y|X=0)): \", media_Y_X_0)\n",
    "print(\"(E(Y|X=1)- E(Y|X=0)): \", dif_media_Y_X)\n",
    "print(\"M√©dia de u: \", media_u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hip√≥tese 3**\n",
    "\n",
    "N√£o multicolinearidade (posto completo da matriz X). A hip√≥tese 3 define que as vari√°veis independentes **n√£o s√£o perfeitamente correlacionadas entre si**. \n",
    "\n",
    "Considere a Matriz X(2x2) abaixo:\n",
    "\n",
    "$ X = \\begin{bmatrix} 1 & 3 \\\\ 4 & 12 \\end{bmatrix} $\n",
    "\n",
    "Sua transposta √©:\n",
    "\n",
    "$ X¬¥ = \\begin{bmatrix} 1 & 4 \\\\ 3 & 12 \\end{bmatrix} $\n",
    "\n",
    "O produto da transposta com a matriz X √©:\n",
    "\n",
    "$ X¬¥X = \\begin{bmatrix} 1 & 4 \\\\ 3 & 12 \\end{bmatrix} \\begin{bmatrix} 1 & 3 \\\\ 4 & 12 \\end{bmatrix} = \\begin{bmatrix} 17 & 51 \\\\ 51 & 153 \\end{bmatrix} $\n",
    "\n",
    "Para calcular a matriz inversa $X¬¥X^{-1}$ ($A^{-1}$):\n",
    "\n",
    "$ A^{-1} = \\frac{1}{det(A)} .  Adjunta $\t\n",
    "\n",
    "$ ùê¥ùëëùëóùë¢ùëõùë°ùëé = (ùê∂ùëúùëì)^ùëá$ \n",
    "\n",
    "$ùê∂ùëúùëì=(‚àí1)^{(ùëñ+ùëó)}.det(MC)$\n",
    "\n",
    "O det(MC) √© o determinante da matriz resultante da elimina√ß√£o da linha e da coluna.\n",
    "\n",
    "Ent√£o, eu chamo a sua aten√ß√£o que para calcular a inversa de $X¬¥X$, no in√≠cio do procedimento, precisamos calcular o determinante da matriz. **Qual o determinante da matriz $X¬¥X$?**\n",
    "\n",
    "Precisamos do posto completo para a inversa existir e identificarmos os coeficientes do modelo.\n",
    "\n",
    "\n",
    "**Hip√≥tese 4**\n",
    "\n",
    "A **vari√¢ncia esf√©rica do erro** implica em duas condi√ß√µes principais:\n",
    "\n",
    "* **Homocedasticidade**: Esta condi√ß√£o requer que a vari√¢ncia do erro condicional a $ X $ seja constante e positiva:\n",
    "\n",
    "$$\n",
    "   E(\\epsilon_{i}^{2} | X) = \\sigma^{2} > 0\n",
    "$$\n",
    "\n",
    "Isso indica que a vari√¢ncia dos erros √© a mesma para todos os indiv√≠duos, independentemente dos valores de $ X $.\n",
    "\n",
    "* **Aus√™ncia de correla√ß√£o entre os erros dos indiv√≠duos (n√£o correla√ß√£o espacial)**: Esta condi√ß√£o implica que a covari√¢ncia entre os erros de dois indiv√≠duos distintos, \\( i \\) e \\( j \\), √© zero:\n",
    "\n",
    "$$\n",
    "   E(\\epsilon_{i}\\epsilon_{j} | X) = 0 \\quad \\text{para } i \\neq j\n",
    "$$\n",
    "\n",
    "Isso assegura que n√£o h√° correla√ß√£o entre os erros dos diferentes indiv√≠duos, ou seja, os erros s√£o independentes entre si condicional a \\( X \\).\n",
    "\n",
    "Combinando essas duas condi√ß√µes, temos que a matriz de vari√¢ncia-covari√¢ncia dos erros condicional a \\( X \\) √© dada por:\n",
    "\n",
    "$$\n",
    "E(\\epsilon \\epsilon^{\\prime} | X) = \\sigma^{2} I_{n}\n",
    "$$\n",
    "\n",
    "onde $ I_{n} $ √© a matriz identidade de ordem $ n $. Isso significa que a vari√¢ncia dos erros √© esf√©rica, isto √©, a mesma em todas as dire√ß√µes (vari√¢ncia constante) e os erros s√£o ortogonais entre si (n√£o correlacionados).\n",
    "\n",
    "\n",
    "* Vejamos a Homocedasticidade na figura:\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"images/distr_02.PNG\"  alt=\"Imagem\" style=\"width: 500px;\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "Em termos matriciais, a hip√≥tese 4 de homocedasticidade √© escrita como:\n",
    "\n",
    "$$ E(\\epsilon \\epsilon^{¬¥}|X) = \\sigma^{2}I_{n} = \\begin{bmatrix} \\sigma^{2} & 0 & 0 & ... & 0 \\\\ 0 & \\sigma^{2} & 0 & ... & 0 \\\\ 0 & 0 & \\sigma^{2} & ... & 0 \\\\ ... & ... & ... & ... & ... \\\\ 0 & 0 & 0 & ... & \\sigma^{2} \\end{bmatrix} = \\Omega $$\n",
    "\n",
    "Onde $\\Omega$ √© a matriz de covari√¢ncia dos erros. A matriz $\\Omega$ √© diagonal e todos os elementos fora da diagonal s√£o zero. A vari√¢ncia do erro √© constante e a covari√¢ncia entre os erros √© zero.\n",
    "\n",
    "**Considerando a heterocedasticidade**, a matriz $\\Omega$ √© diagonal, entretanto, os elementos da diagonal n√£o s√£o iguais. A vari√¢ncia do erro n√£o √© constante e a covari√¢ncia entre os erros √© zero.\n",
    "\n",
    "* Vejamos a Heterocedasticidade na figura:\n",
    " \n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"images/distr_03.PNG\"  alt=\"Imagem\" style=\"width: 500px;\"/>\n",
    "</div>\n",
    "\n",
    "Em termos matriciais, a falha na hip√≥tese 4, ou seja, **a exist√™ncia de heterocedasticidade** √© escrita como:\n",
    "\n",
    "$$ E(\\epsilon \\epsilon^{¬¥}|X) = \\begin{bmatrix} \\sigma_{1}^{2} & 0 & 0 & ... & 0 \\\\ 0 & \\sigma_{2}^{2} & 0 & ... & 0 \\\\ 0 & 0 & \\sigma_{3}^{2} & ... & 0 \\\\ ... & ... & ... & ... & ... \\\\ 0 & 0 & 0 & ... & \\sigma_{n}^{2} \\end{bmatrix} = \\Omega $$\n",
    "\n",
    "\n",
    "\n",
    "Ent√£o, sob as quatro hip√≥teses:\n",
    "\n",
    "* Linearidade\n",
    "* Exogeneidade estrita\n",
    "* N√£o-Multicolinearidade\n",
    "* Vari√¢ncia esf√©rica do erro (homocedasticidade e n√£o correla√ß√£o espacial dos erros)\n",
    "\n",
    "O estimador OLS √© o estimador mais eficiente na classe dos estimadores lineares n√£o viesados **(BLUE - Best Linear Unbiased Estimator)**.\n",
    "\n",
    "**Descompondo o Conceito de BLUE**:\n",
    "\n",
    "* **Best** (Melhor)\n",
    "  * Entre todos os estimadores lineares e n√£o viesados, o estimador BLUE tem a menor vari√¢ncia. Isso significa que ele √© o mais eficiente, fornecendo as estimativas mais precisas (menor dispers√£o) poss√≠vel para o par√¢metro em quest√£o.\n",
    "* **Linear**\n",
    "  * O estimador √© linear nas observa√ß√µes, o que significa que ele pode ser expresso como uma combina√ß√£o linear das vari√°veis independentes (ou dos dados). Em um modelo de regress√£o linear, por exemplo, os coeficientes de regress√£o s√£o estimadores lineares dos par√¢metros.\n",
    "* **Unbiased** (N√£o viesado)\n",
    "  * Um estimador √© n√£o viesado se, em m√©dia, ele retorna o verdadeiro valor do par√¢metro. Em outras palavras, a expectativa matem√°tica do estimador √© igual ao par√¢metro que ele est√° estimando: $E(\\hat{\\beta}) = \\beta$.\n",
    "* **Estimator** (Estimador)\n",
    "  * Um estimador √© uma regra ou f√≥rmula que usamos para calcular uma estimativa de um par√¢metro desconhecido com base nos dados dispon√≠veis.\n",
    "\n",
    "**Teorema de Gauss-Markov**\n",
    "\n",
    "O conceito de BLUE est√° fortemente associado ao Teorema de Gauss-Markov. Este teorema afirma que, sob certas condi√ß√µes (como linearidade, exogeneidade, homocedasticidade e aus√™ncia de multicolinearidade perfeita), o estimador dos m√≠nimos quadrados ordin√°rios (MQO) √© o BLUE para os coeficientes de um modelo de regress√£o linear.\n",
    "Para provar temos que mostrar:\n",
    "* O estimador √© linear\n",
    "* O estimador √© n√£o viesado\n",
    "* O estimador tem a menor vari√¢ncia\n",
    "\n",
    "**Hip√≥tese 5**\n",
    "\n",
    "O termo de erro √© normalmente distribu√≠do. Ou seja, $\\epsilon \\sim N(0, \\sigma^{2})$. Em outras palavras, a distribui√ß√£o condicional de $\\epsilon$ em $X$ √© conjuntamente normal.\n",
    "\n",
    "As 5 hip√≥teses conjuntamente implicam que a distribui√ß√£o condicional de $\\epsilon$ em $X$ √© normal com m√©dia zero e vari√¢ncia constante:\n",
    "\n",
    "$$ \\epsilon|X \\sim N(0, \\sigma^{2}I_{n}) $$\n",
    "\n",
    "Isso quer dizer que a distribui√ß√£o de $\\epsilon$ condicional em $X$ n√£o depende de $X$ (S√£o independentes). Essa quinta hip√≥tese √© importante para a infer√™ncia estat√≠stica (Teste-t e Teste-F).\n",
    "\n",
    "\n",
    "Ent√£o, sob as cinco hip√≥teses:\n",
    "\n",
    "* Linearidade\n",
    "* Exogeneidade estrita\n",
    "* N√£o-Multicolinearidade\n",
    "* Vari√¢ncia esf√©rica do erro\n",
    "* Termo de erro √© normalmente distribu√≠do\n",
    "\n",
    "O estimador OLS √© o estimador mais eficiente na classe dos estimadores lineares n√£o viesados **(BLUE - Best Linear Unbiased Estimator)** e √© poss√≠vel realizar infer√™ncia estat√≠stica.\n",
    "\n",
    "* *Observa√ß√£o: Essa hip√≥tese 5 √© importante porque garante que os estimadores dos coeficientes $\\beta$ no modelo de regress√£o s√£o eficientes e que as infer√™ncias estat√≠sticas (como os testes t e F) ser√£o v√°lidas. Quando o termo de erro √© normalmente distribu√≠do, as estimativas do MQO s√£o tamb√©m as melhores estimativas lineares n√£o viesadas (BLUE - Best Linear Unbiased Estimators) e t√™m distribui√ß√£o normal. Em resumo, a Hip√≥tese 5 sobre a normalidade dos erros √© crucial para que os resultados inferenciais (testes de hip√≥tese, intervalos de confian√ßa, etc.) no modelo de regress√£o linear sejam v√°lidos e precisos.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### √Ålgebra do OLS\n",
    "\n",
    "#### **N√£o vi√©s** e **Consist√™ncia**\n",
    "\n",
    "Considere que o m√©todo OLS busca o argumento b que minimiza o quadrado dos res√≠duos. Vejamos em termos alg√©bricos:\n",
    "\n",
    "$$ \\beta = argmin(b)E[(Y_{i}-X_{i}b)^2] $$\n",
    "\n",
    "A condi√ß√£o de primeira ordem (CPO):\n",
    "\n",
    "$$ E[X¬¥_{i}(Y_{i}-X_{i}b)]=0 $$\n",
    "\n",
    "Sob a hip√≥tese de posto completo √© poss√≠vel ter a inversa $E[X_{i}¬¥X_{i}]^{-1}$, e isolamos o beta estimado (b) :\n",
    "\n",
    "$$ b = E[X_{i}¬¥X_{i}]^{-1}E[X_{i}¬¥Y_{i}] $$\n",
    "\n",
    "Considere a regress√£o populacional dada por:\n",
    "\n",
    "$$ Y_{i} = X_{i}\\beta + u_{i} $$\n",
    "\n",
    "Podemos substituir a regress√£o populacional na estimativa de beta amostral:\n",
    "\n",
    "$$ b = E[X_{i}¬¥X_{i}]^{-1}E[X_{i}¬¥ Y_{i} ] $$\n",
    "\n",
    "* *Observa√ß√£o: A regress√£o populacional √© a forma te√≥rica da rela√ß√£o entre a vari√°vel dependente $Y_{i}$ e as vari√°veis independentes $X_{i}$ com base na popula√ß√£o inteira. Nessa equa√ß√£o, $\\beta$ representa os verdadeiros par√¢metros desconhecidos e $u_{i}$ √© o termo de erro ou dist√∫rbio, que captura todos os fatores que influenciam $Y_{i}$ al√©m de $X_{i}$. Substituir a regress√£o populacional na estimativa amostral de $\\beta$ √© uma etapa crucial para entender o m√©todo de estima√ß√£o de M√≠nimos Quadrados Ordin√°rios (MQO). Ao fazer isso, estamos usando a forma te√≥rica (populacional) da regress√£o para derivar o estimador amostral $b$ para $\\beta$.*\n",
    "\n",
    "temos, teoricamente:\n",
    "\n",
    "$$ b = E[X_{i}¬¥X_{i}]^{-1}E[X_{i}¬¥(X_{i}\\beta + u_{i})] $$\n",
    "\n",
    "Logo:\n",
    "\n",
    "$$ b = \\beta + E[X_{i}¬¥X_{i}]^{-1}E[X_{i}¬¥u_{i}] $$\n",
    "\n",
    "\n",
    "ou\n",
    "\n",
    "$$ b= \\beta+\\frac{\\operatorname{Cov}(X, u)}{\\operatorname{Var}(X)} $$\n",
    "\n",
    "\n",
    "**N√£o-vi√©s**\n",
    "\n",
    "O estimador OLS √© n√£o viesado se, em m√©dia, ele retorna o verdadeiro valor do par√¢metro populacional $\\beta$. Isso significa que a expectativa do estimador $b$ √© igual ao valor verdadeiro de $\\beta$. Para que $b$ seja n√£o viesado, precisamos que $E[b] = \\beta$. Observe que isso ocorrer√° se $E[X¬¥u] = 0$. Sob a hip√≥tese de exogeneidade estrita, assumimos que $E[u|X] = 0$, o que implica que $E[X¬¥u] = X¬¥E[u] = 0$. Portanto, o estimador OLS $b$ √© n√£o viesado, pois sua expectativa √© igual ao verdadeiro valor do par√¢metro $\\beta$. Isso garante que, em m√©dia, o OLS fornece uma estimativa correta do par√¢metro, sem sistematicamente superestimar ou subestimar o valor verdadeiro.\n",
    "\n",
    "\n",
    "**Consist√™ncia**\n",
    "\n",
    "A consist√™ncia do estimador de m√≠nimos quadrados ordin√°rios (OLS) significa que, √† medida que o tamanho da amostra aumenta, o estimador converge em probabilidade para o verdadeiro valor do par√¢metro populacional $\\beta$. Em outras palavras, conforme $n \\rightarrow \\infty$, o estimador $b$ converge para o verdadeiro valor do par√¢metro $\\beta$. Para mostrar que $b$ √© consistente, precisamos mostrar que: $b - \\beta \\rightarrow 0$ conforme $n \\rightarrow \\infty$, ou, equivalentemente, $(X¬¥X)^{-1}X¬¥u \\rightarrow 0$. Pela lei dos grandes n√∫meros, $\\frac{1}{n}X¬¥X \\rightarrow E[X¬¥X]$ (uma matriz positiva definida) e $\\frac{1}{n}X¬¥u \\rightarrow E[X¬¥u]$. Assim, $(X¬¥X)^{-1}X¬¥u \\rightarrow E[X¬¥X]^{-1}E[X¬¥u]$. Sob a hip√≥tese de exogeneidade estrita, $E[X¬¥u] = 0$, o que implica que: $\\frac{1}{n}X¬¥u \\rightarrow 0$. Portanto, $(X¬¥X)^{-1}X¬¥u \\rightarrow 0$ e, consequentemente, $b - \\beta \\rightarrow 0$.A ideia √© que a consist√™ncia do OLS surge porque, com um n√∫mero suficientemente grande de observa√ß√µes, as flutua√ß√µes aleat√≥rias dos erros $u$ s√£o \"anuladas\" em m√©dia. Assim, o estimador OLS se \"fixa\" no verdadeiro valor de $\\beta$ conforme a quantidade de dados aumenta.\n",
    "\n",
    "\n",
    "Posteriormente, ampliaremos a discuss√£o sobre a import√¢ncia da hip√≥tese de exogeneidade estrita no contexto de **identifica√ß√£o causal**.\n",
    "\n",
    "\n",
    "#### **Efici√™ncia**\n",
    "\n",
    "Para fazer **INFER√äNCIA ESTAT√çSTICA**, precisamos da **variabilidade dos coeficientes estimados** (mais especificadamente, da vari√¢ncia - $Var(b)$ e seu erro padr√£o).\n",
    "\n",
    "Utilizando a defini√ß√£o de vari√¢ncia e considerando que (b) √© n√£o tendencioso, temos:\n",
    "\n",
    "$$ Var(b) = E[b - \\beta]^{2} $$\n",
    "\n",
    "Vimos que:\n",
    "\n",
    "$$ b = \\beta + E[X_{i}¬¥X_{i}]^{-1}E[X_{i}¬¥u_{i}] $$\n",
    "\n",
    "$$ b - \\beta = E[X_{i}¬¥X_{i}]^{-1}E[X_{i}¬¥u_{i}] $$\n",
    "\n",
    "Pela defini√ß√£o de vari√¢ncia:\n",
    "\n",
    "$$ Var(b) = E[(b - \\beta)^{2}] = E[(b - \\beta)(b - \\beta)^{¬¥}] $$\n",
    "\n",
    "logo, \n",
    "\n",
    "$$ Var(b|X) = (E[X_{i}¬¥X_{i}]^{-1}E[X_{i}¬¥u_{i}])(E[u_{i}¬¥X_{i}]E[X_{i}X_{i}¬¥]^{-1}) $$\n",
    "\n",
    "$$ Var(b|X) = E[X_{i}¬¥X_{i}^{-1}X_{i}¬¥u_{i}u_{i}^{¬¥}X_{i}X_{i}¬¥X_{i}^{-1}] $$\n",
    "\n",
    "$$ Var(b|X) = E[(X_{i}¬¥X_{i}^{-1})X_{i}¬¥[u_{i}u_{i}^{¬¥}]X_{i}(X_{i}¬¥X_{i}^{-1})] $$\n",
    "\n",
    "Sob Homocedasticidade (Hip3), $E[\\epsilon_{i}^{2}|X] = \\sigma^{2}$,\n",
    "\n",
    "$$ Var(b|X) = \\sigma^{2}E[(X_{i}¬¥X_{i}^{-1})X_{i}¬¥X_{i}(X_{i}¬¥X_{i}^{-1})] $$\n",
    "\n",
    "Logo, \n",
    "\n",
    "$$ \\operatorname{Var}(b|X) = \\sigma^{2}E[X_{i}¬¥X_{i}]^{-1} $$\n",
    "\n",
    "\n",
    " **Efici√™ncia**\n",
    "\n",
    "Um estimador √© dito eficiente se, dentre todos os estimadores lineares e n√£o viesados, ele tiver a menor vari√¢ncia. O estimador OLS para $b$ √© dado por: $ b = (X'X)^{-1}X'Y $ (podemos expressar isso como $b = CY$, onde $C = (X'X)^{-1}X'$). Considerando as condi√ß√µes de (i) linearidade, (ii) exogeneidade estrita, (iii) homocedasticidade e (iv) aus√™ncia de multicolinearidade perfeita (as quatro primeiras hip√≥teses do OLS), o Teorema de Gauss-Markov afirma que a vari√¢ncia do estimador OLS: $ \\operatorname{Var}(b|X) = \\sigma^2 (X'X)^{-1} $ √© a menor vari√¢ncia poss√≠vel entre todos os estimadores lineares n√£o viesados. Isso significa que $b$ √© o Best Linear Unbiased Estimator (BLUE). Para mostrar isso, precisamos comparar o OLS com qualquer outro estimador linear n√£o viesado, denotado por $\\tilde{b}$, e demonstrar que: $ \\operatorname{Var}(\\tilde{b}) \\geq \\operatorname{Var}(b) $. Considere uma matriz $A$ $(k \\times n)$ que satisfa√ßa a condi√ß√£o de n√£o vi√©s $AX = I_k$, onde $I_k$ √© a matriz identidade de ordem $k$. Isso garante que: $ E[\\tilde{b}] = E[AY] = AX\\beta = \\beta $. Assim, para que $\\tilde{b}$ seja n√£o viesado, precisamos de $AX = I_k$. A vari√¢ncia de $\\tilde{b}$ √© dada por: $ \\operatorname{Var}(\\tilde{b}) = \\operatorname{Var}(AY) = A \\operatorname{Var}(Y) A' = A \\sigma^2 I_n A' = \\sigma^2 AA' $. Substituindo $A = (X'X)^{-1}X'$ na express√£o para a vari√¢ncia, obtemos:$ \\operatorname{Var}(\\tilde{b}|X) = \\sigma^2 (X'X)^{-1} = \\operatorname{Var}(b|X) $. Portanto, o estimador OLS √© eficiente porque ele atinge a menor vari√¢ncia poss√≠vel entre todos os estimadores lineares n√£o viesados. Em outras palavras, o estimador OLS √© o estimador BLUE (Best Linear Unbiased Estimator) para os coeficientes de um modelo de regress√£o linear.\n",
    "\n",
    " \n",
    "Assumindo as quatro hip√≥teses, mais a hip√≥tese de normalidade dos erros:\n",
    "\n",
    "$$ \\epsilon|X \\sim N(0, \\sigma^{2}I_{n}) $$\n",
    "\n",
    "A distribui√ß√£o de $\\epsilon$ condicional em $X$ n√£o depende de $X$ (S√£o independentes). Assim, as distribui√ß√µes marginais e incondicionais de $\\epsilon$ s√£o normais ($\\epsilon \\sim N(0, \\sigma^{2}I_{n})$). E o erro amostra ($b-\\beta$) √© linear em $\\epsilon$ dado $X$. Sob essas hip√≥teses:\n",
    "\n",
    "$$ b - \\beta \\sim N(0 , \\sigma^{2}(X¬¥X)^{-1}) $$\n",
    "\n",
    "Para testar a hip√≥tese individual de um coeficiente:\n",
    "\n",
    "$$ H_{0}: b_{k} = \\bar{\\beta}_{k} $$\n",
    "$$ H_{1}: b_{k} \\neq \\bar{\\beta}_{k} $$\n",
    "\n",
    "a um n√≠vel de signific√¢ncia $\\alpha$. logo,\n",
    "\n",
    "$$ (b_{k} - \\bar{\\beta_{k}})| X \\sim N(0, \\sigma^{2}(X¬¥X)^{-1}_{kk}) $$\n",
    "\n",
    "definindo a raz√£o $z_{k}$ pela divis√£o de $b_{k} - \\bar{\\beta_{k}}$ pelo desvio padr√£o :\n",
    "\n",
    "$$ z_{k} = \\frac{b_{k} - \\bar{\\beta_{k}}}{\\sqrt{\\sigma^{2}(X¬¥X)^{-1}_{kk}}} $$\n",
    "\n",
    "ent√£o a distribui√ß√£o de $z_{k}$ √© $N(0,1)$ (distriui√ß√£o normal padr√£o). Mas n√£o sabemos o verdadeiro valor de $\\sigma^{2}$, ent√£o usamos a estimativa da vari√¢ncia dos erros ($\\hat{\\sigma}^{2}$, ou $s^{2}$). A estat√≠stica ap√≥s a substitui√ß√£o √© chamada de **t-Student**, e o denominador dessa estat√≠stica √© o erro padr√£o de $b_{k}$ do OLS (SE).\n",
    "\n",
    "$$ SE(b_{k}) = \\sqrt{\\hat{\\sigma}^{2}(X¬¥X)^{-1}_{kk}} $$\n",
    "\n",
    "Ent√£o, supondo as 5 hip√≥teses e sob a hip√≥tese nula $H_{0}: b_{k} = \\bar{\\beta_{k}} $, a estat√≠stica t √© dada por:\n",
    "\n",
    "$$ t_{k} = \\frac{b_{k} - \\bar{\\beta_{k}}}{SE(b_{k})} $$\n",
    "\n",
    "\n",
    "Em termos de estimativa amostral:\n",
    "\n",
    "\n",
    "$$ t_{k} = \\frac{b_{k} - \\bar{b_{k}}}{SE(b_{k})} = \\frac{b_{k} - \\bar{b_{k}}}{\\sqrt{Var(b|X)}} = \\frac{b_{k} - \\bar{b_{k}}}{\\sqrt{\\hat{\\sigma}^{2}(X¬¥X)^{-1}_{kk}}} = \\frac{b_{k} - \\bar{b_{k}}}{\\sqrt{\\frac{\\sum{u_{i}^{2}}/(n-k)}{\\sum(x_{i}-\\bar{x})^{2}}}} $$\n",
    "\n",
    "onde $u_{i} \\sim N(0, \\sigma^{2})$.\n",
    "\n",
    "**Repare**\n",
    "* Temos 3 termos \"vari√¢ncia\" aqui, Vari√¢ncia dos coeficientes estimados e Vari√¢ncia dos res√≠duos e Vari√¢ncia das Covari√°veis (vari√°veis explicativas).\n",
    "* Se a **vari√¢ncia dos erros** aumentar ($\\hat{\\sigma}^{2}$), a **vari√¢ncia dos coeficientes** estimados tamb√©m aumentar√° ($Var(b|X)$). \n",
    "* Se as vari√°veis $X$ variam pouco, a **vari√¢ncia dos coeficientes** estimados aumentar√°.\n",
    "* Logo, **precisamos de varia√ß√£o nas vari√°veis explicativas** para estimar os coeficientes com precis√£o, e uma **vari√¢ncia dos res√≠duos menor e constante**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regra de Decis√£o para o Teste-t\n",
    "\n",
    "##### Passo 1: Defina as Hip√≥teses\n",
    "- **Hip√≥tese Nula (H0)**: A vari√°vel $X_k$ n√£o tem efeito sobre Y (o coeficiente associado √† X √© estatisticamente zero).\n",
    "- **Hip√≥tese Alternativa (H1)**: A vari√°vel $X_k$ tem efeito sobre Y (o coeficiente associado √† X n√£o √© estat√≠sticamente zero).\n",
    "\n",
    "##### Passo 2: Determine o N√≠vel de Signific√¢ncia ($\\alpha $)\n",
    "- O **n√≠vel de signific√¢ncia** √© a probabilidade de cometer um erro ao rejeitar a hip√≥tese nula quando ela √© verdadeira. Comumente usado s√£o 1%, 5% ou 10%.\n",
    "- Na tabela t, encontre o valor cr√≠tico $t_{\\alpha/2}(n-K)$, onde \\(n\\) √© o n√∫mero de observa√ß√µes e \\(K\\) √© o n√∫mero de coeficientes no modelo. Este valor cr√≠tico delimita a √°rea $ \\alpha/2 $ em cada cauda da distribui√ß√£o t.\n",
    "\n",
    "A rela√ß√£o √© expressa como:\n",
    "$$ \\text{Prob}(-t_{\\alpha/2}(n-K) < t < t_{\\alpha/2}(n-K)) = 1 - \\alpha $$\n",
    "\n",
    "Ou seja, a express√£o signfica que a probabilidade de que a estat√≠stica t calculada a partir dos dados caia dentro do intervalo delimitado pelos valores cr√≠ticos √© $1 - \\alpha$.\n",
    "\n",
    "##### Passo 3: Tome a Decis√£o\n",
    "- **Aceite H0** se $ |t_k| < t_{\\alpha/2}(n-K) $, ou seja, se o valor absoluto do t calculado para o coeficiente $X_k$ √© menor que o valor cr√≠tico.\n",
    "- **Rejeite H0** se $ |t_k| \\ge t_{\\alpha/2}(n-K) $, ou seja, se o valor absoluto do t calculado √© maior ou igual ao valor cr√≠tico.\n",
    "\n",
    "##### Explica√ß√£o Intuitiva\n",
    "1. **Hip√≥teses**: Voc√™ come√ßa com a suposi√ß√£o (H0) de que a vari√°vel $X_k$ n√£o tem impacto. Se os dados mostrarem um grande desvio dessa suposi√ß√£o, voc√™ considerar√° que $X_k$ realmente tem impacto (H1).\n",
    "2. **Signific√¢ncia**: Decida o qu√£o seguro voc√™ quer estar ao rejeitar H0. Um n√≠vel de signific√¢ncia de 5% significa que h√° uma chance de 5% de voc√™ estar cometendo um erro ao rejeitar H0.\n",
    "3. **Decis√£o**: Compare o t calculado para $X_k$ com um valor cr√≠tico da tabela t. Se o t calculado estiver fora do intervalo aceit√°vel, rejeite H0; caso contr√°rio, aceite H0.\n",
    "\n",
    "\n",
    "### Intervalo de Confian√ßa (IC)\n",
    "\n",
    "O intervalo de confian√ßa nos ajuda a entender a precis√£o da estimativa do coeficiente $ \\beta_k $. Ele fornece um intervalo de valores poss√≠veis para $ \\beta_k $ com uma certa confian√ßa.\n",
    "\n",
    "##### Passo 3 Reescrito\n",
    "\n",
    "Podemos reescrever a regra de decis√£o do passo 3 em termos do coeficiente estimado $ b_k $ e do erro padr√£o $ SE(b_k) $:\n",
    "\n",
    "$$ -t_{\\alpha/2}(n-K) < \\frac{b_k - \\beta_k}{SE(b_k)} < t_{\\alpha/2}(n-K) $$\n",
    "\n",
    "Isso pode ser rearranjado para:\n",
    "\n",
    "$$ b_k - t_{\\alpha/2}(n-K)SE(b_k) < \\beta_k < b_k + t_{\\alpha/2}(n-K)SE(b_k) $$\n",
    "\n",
    "##### Interpreta√ß√£o Intuitiva\n",
    "\n",
    "Aceitamos a hip√≥tese nula se e somente se o valor hipotetizado de $ \\beta_k $ estiver dentro do intervalo de confian√ßa. Isso significa que estamos verificando se $ \\beta_k $ cai dentro do intervalo que esperamos, com base nos nossos dados:\n",
    "\n",
    "$$ IC = \\left[ b_k - SE(b_k) \\cdot t_{\\alpha/2}(n-K), b_k + SE(b_k) \\cdot t_{\\alpha/2}(n-K) \\right] $$\n",
    "\n",
    "##### Resumo do IC\n",
    "- **Intervalo de Confian√ßa**: √â um intervalo ao redor do coeficiente estimado $ b_k $ onde acreditamos que o verdadeiro valor $ \\beta_k $ est√° localizado, com um certo n√≠vel de confian√ßa (1 - $\\alpha$).\n",
    "- **N√≠vel de Confian√ßa**: Se escolhermos **um n√≠vel de signific√¢ncia** ($\\alpha$) de 5%, **o n√≠vel de confian√ßa** ser√° 95%. Isso significa que, se repet√≠ssemos o estudo muitas vezes, 95% dos intervalos de confian√ßa calculados conteriam o verdadeiro valor do coeficiente.\n",
    "- **Decis√£o**: Se o valor hipotetizado de $ \\beta_k $ est√° dentro deste intervalo, n√£o temos evid√™ncias suficientes para rejeitar a hip√≥tese nula. Caso contr√°rio, rejeitamos a hip√≥tese nula.\n",
    "\n",
    "### p-Valor - Regra de Decis√£o do Teste-t Usando o P-Valor\n",
    "\n",
    "Em vez de encontrar o valor cr√≠tico $ t_{\\alpha/2}(n-K) $, podemos usar o p-valor para tomar a decis√£o. Aqui est√° uma explica√ß√£o passo a passo:\n",
    "\n",
    "##### C√°lculo do P-Valor\n",
    "\n",
    "1. **Calcule a Estat√≠stica t:** Primeiro, calculamos a estat√≠stica t para o coeficiente $ t_k $.\n",
    "\n",
    "2. **Encontre a Probabilidade:** Determine a probabilidade de obter um valor absoluto de t maior que $ |t_k| $. Esta probabilidade √©:\n",
    "\n",
    "$$ p = 2 \\times \\text{Prob}(t > |t_k|) $$\n",
    "\n",
    "Porque a distribui√ß√£o t √© sim√©trica em torno de zero, temos:\n",
    "\n",
    "$$ \\text{Prob}(t > |t_k|) = \\text{Prob}(t < -|t_k|) $$\n",
    "\n",
    "Assim, a probabilidade de $ t $ estar entre $ -|t_k| $ e $ |t_k| $ √©:\n",
    "\n",
    "$$ \\text{Prob}(-|t_k| < t < |t_k|) = 1 - p $$\n",
    "\n",
    "##### Tomando a Decis√£o\n",
    "\n",
    "**Aceitamos H0 se $ p > \\alpha $ e rejeitamos H0 caso contr√°rio.**\n",
    "\n",
    "Em outras palavras, se o p-valor for menor ou igual ao n√≠vel de signific√¢ncia ($\\alpha$), rejeitamos a hip√≥tese nula. Caso contr√°rio, aceitamos a hip√≥tese nula.\n",
    "\n",
    "##### Interpreta√ß√£o Intuitiva do P-Valor\n",
    "\n",
    "- **P-Valor:** O p-valor representa a probabilidade de obter um valor da estat√≠stica t igual ou mais extremo do que o observado, assumindo que a hip√≥tese nula seja verdadeira.\n",
    "  \n",
    "- **Significado Pr√°tico:** Um p-valor baixo indica que √© muito improv√°vel observar um valor da estat√≠stica t t√£o extremo apenas por acaso se a hip√≥tese nula for verdadeira. Portanto, um **p-valor baixo sugere evid√™ncia contra a hip√≥tese nula.**\n",
    "\n",
    "##### Exemplo Pr√°tico\n",
    "\n",
    "- **P-Valor Baixo:** Um p-valor de 0.0001 significa que h√° apenas 0.01% de chance de obter um valor t t√£o extremo ou mais extremo se a hip√≥tese nula for verdadeira. Isso indica forte evid√™ncia contra a hip√≥tese nula.\n",
    "  \n",
    "- **Decis√£o Baseada no P-Valor:** Se o p-valor √© menor que 0.05 (5%), rejeitamos a hip√≥tese nula com uma confian√ßa de 95%.\n",
    "\n",
    "##### Erros em Testes de Hip√≥teses\n",
    "Em testes de hip√≥teses, podem ocorrer dois tipos principais de erros ao tomar decis√µes:\n",
    "\n",
    "- **Erro Tipo I (Falso Positivo):** Rejeitar a hip√≥tese nula quando ela √© verdadeira. A probabilidade de cometer este erro √© o n√≠vel de signific√¢ncia ($\\alpha$).\n",
    "  - Exemplo: Suponha que estamos testando se um novo medicamento √© eficaz (hip√≥tese alternativa) contra um placebo (hip√≥tese nula). Se cometemos um Erro Tipo I, conclu√≠mos que o medicamento funciona quando, na verdade, ele n√£o tem efeito.\n",
    "- **Erro Tipo II (Falso Negativo):** Aceitar a hip√≥tese nula quando ela √© falsa.\n",
    "  - Exemplo: Usando o mesmo exemplo do medicamento, se cometemos um Erro Tipo II, conclu√≠mos que o medicamento n√£o funciona quando, na verdade, ele √© eficaz.\n",
    "\n",
    "Todas as Situa√ß√µes Poss√≠veis em testes, vamos pensar num exemplo onde testamos dois m√©todos de ensino distintos, um mais novo e outro mais tradicional.\n",
    "\n",
    "1. **$H_0$ √© Verdadeira e Aceitamos $H_0$** (Decis√£o Correta)\n",
    "   - Conclu√≠mos corretamente que n√£o h√° diferen√ßa entre os m√©todos de ensino.\n",
    "\n",
    "2. **$H_0$ √© Verdadeira e Rejeitamos $H_0$** (Erro Tipo I)\n",
    "   - Incorretamente conclu√≠mos que o novo m√©todo de ensino √© mais eficaz quando n√£o √©.\n",
    "\n",
    "3. **$H_0$ √© Falsa e Rejeitamos $H_0$** (Decis√£o Correta)\n",
    "   - Conclu√≠mos corretamente que o novo m√©todo de ensino √© mais eficaz.\n",
    "\n",
    "4. **$H_0$ √© Falsa e Aceitamos $H_0$** (Erro Tipo II)\n",
    "   - Incorretamente conclu√≠mos que n√£o h√° diferen√ßa entre os m√©todos de ensino quando, na verdade, o novo m√©todo √© mais eficaz.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R-quadrado e R-quadrado ajustado (Poder Explicativo do Modelo)\n",
    "\n",
    "O R-quadrado √© uma medida de ajuste do modelo, e do poder explicativo das vari√°veis independentes. Em outras palavras, ele mede a propor√ß√£o da variabilidade da vari√°vel dependente que √© explicada pelas vari√°veis independentes. Podemos decompor a variabilidade da vari√°vel dependente em duas partes: a parte explicada pelas vari√°veis independentes e a parte n√£o explicada (erro).\n",
    "\n",
    "**R-2**\n",
    "\n",
    "$$ y¬¥y = (\\hat{y} + e)¬¥(\\hat{y} + e) $$\n",
    "\n",
    "$$ y¬¥y = \\hat{y}¬¥\\hat{y} + e¬¥e + 2\\hat{y}¬¥e $$\n",
    "\n",
    "Como $\\hat{y} = Xb$, temos:\n",
    "\n",
    "$$ y¬¥y = \\hat{y}¬¥\\hat{y} + e¬¥e + 2Xb¬¥e $$\n",
    "\n",
    "sob a hip√≥tese de exogeneidade estrita, $E[X¬¥e] = 0$\n",
    "\n",
    "$$ y¬¥y = \\hat{y}¬¥\\hat{y} + e¬¥e $$\n",
    "\n",
    "por defini√ß√£o\n",
    "\n",
    "$$ R^{2} \\equiv \\frac{\\hat{y}¬¥\\hat{y}}{y¬¥y} $$\n",
    "\n",
    "Voltando a rela√ß√£o, e dividindo por $y¬¥y$:\n",
    "\n",
    "$$ 1 = R^{2} - \\frac{e¬¥e}{y¬¥y} $$\n",
    "\n",
    "$$ R^{2} = 1 - \\frac{e¬¥e}{y¬¥y} $$\n",
    "\n",
    "Em termos amostrais:\n",
    "\n",
    "$$ R^{2} = 1 - \\frac{\\sum(u_{i}^{2})}{\\sum(y_{i}-\\bar{y})^{2}} $$\n",
    "\n",
    "\n",
    "\n",
    "O Coeficiente $R^{2}$ tem como limites 0 e 1. Se $R^{2}$ for 1, ent√£o o modelo explica 100% da variabilidade da vari√°vel dependente. Se $R^{2}$ for 0, ent√£o o modelo n√£o explica nada da variabilidade da vari√°vel dependente.\n",
    "\n",
    "Em outras palavras, R-quadrado:\n",
    "\n",
    "$$ R^{2} \\equiv \\frac{SQExp}{SQTot} = 1 - \\frac{SQRes}{SQTot} $$\n",
    "\n",
    "onde:\n",
    "\n",
    "* SQExp = Soma dos quadrados explicados\n",
    "* SQTot = Soma total dos quadrados\n",
    "* SQRes = Soma dos quadrados dos res√≠duos\n",
    "\n",
    "\n",
    "**R-quadrado ajustado**\n",
    "\n",
    "O R-quadrado ajustado √© uma medida de ajuste do modelo que penaliza a inclus√£o de vari√°veis explicativas. Caso contr√°rio, o R-quadrado tenderia a aumentar com a inclus√£o de vari√°veis, mesmo que elas n√£o melhorem o poder explicativo do modelo. Ele √© dado por:\n",
    "\n",
    "$$ R^{2}_{ajustado} = 1 - \\frac{\\sum(u_{i}^{2})/(n-k)}{\\sum(y_{i}-\\bar{y})^{2}/(n-1)} $$\n",
    "\n",
    "\n",
    "#### Outras M√©tricas para Avaliar o Desempenho da Regress√£o\n",
    "\n",
    "As m√©tricas MAE, MSE, e RMSE s√£o usadas principalmente para avaliar o desempenho do modelo na an√°lise de regress√£o. \n",
    "\n",
    "Considerando: \n",
    "* $n$ √© o n√∫mero total de observa√ß√µes.\n",
    "* $y_{i}$ s√£o os valores da vari√°vel de resposta (dependente).\n",
    "* $\\hat{y_{i}}$ s√£o os valores previstos pelo modelo.\n",
    "\n",
    "Vamos definir as m√©tricas.\n",
    "\n",
    "* **Erro M√©dio Absoluto (Mean Absolute Error - MAE)**: √© uma m√©trica usada para avaliar a precis√£o de um modelo de previs√£o ou regress√£o. O MAE calcula o quanto as previs√µes do modelo est√£o desviadas dos valores reais em termos absolutos, ignorando a dire√ß√£o do desvio. Possui a f√≥rmula:\n",
    "\n",
    "$$ MAE = \\frac{1}{n} \\sum_{i=1}^{n} |y_{i} - \\hat{y_{i}} | $$\n",
    "\n",
    "**Interpreta√ß√£o**: Quanto menor o valor do MAE, melhor √© a capacidade do modelo em fazer previs√µes precisas. \n",
    "\n",
    "* **Erro M√©dio Quadr√°tico (Mean Squared Error)**: Assim como o MAE, o MSE mede o qu√£o distantes as previs√µes do modelo est√£o dos valores reais, mas de uma maneira ligeiramente diferente. O MSE calcula a m√©dia dos quadrados das diferen√ßas. Isso significa que o MSE d√° mais peso a erros maiores do que o MAE. Possui a f√≥rmula:\n",
    "\n",
    "$$ MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_{i} - \\hat{y_{i}})^{2} $$\n",
    "\n",
    "**Interpreta√ß√£o**: Assim como no caso do MAE, quanto menor o valor do MSE, melhor √© a capacidade do modelo em fazer previs√µes precisas. No entanto, ao contr√°rio do MAE, o MSE pode ser sens√≠vel a outliers, j√° que os erros s√£o elevados ao quadrado.\n",
    "\n",
    "* **Raiz do Erro M√©dio Quadr√°tico (Root Mean Squared Error - RMSE)**: O RMSE √© calculado tomando a raiz quadrada do MSE, o que retorna a medida de erro na mesma escala que os valores de interesse (por exemplo, a unidade de medida dos dados).\n",
    "\n",
    "$$ RMSE = \\sqrt{MSE}$$\n",
    "\n",
    "**Interpreta√ß√£o**: O RMSE fornece uma interpreta√ß√£o mais intuitiva dos erros de previs√£o, pois est√° na mesma unidade que os valores reais. Isso significa que um RMSE mais baixo indica uma melhor adequa√ß√£o do modelo aos dados observados. Assim como no caso do MSE, o RMSE √© sens√≠vel a outliers, pois os erros s√£o elevados ao quadrado antes de calcular a raiz quadrada. No entanto, o RMSE √© amplamente utilizado porque oferece uma medida mais compreens√≠vel do erro, especialmente quando os valores reais e previstos est√£o em escalas diferentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Teste-F\n",
    "\n",
    "Supondo as cinco hip√≥teses do OLS, podemos fazer testes de hip√≥teses conjuntas sobre os coeficientes estimados. √â possivel testar se coeficientes espec√≠ficos s√£o iguais, ou se s√£o iguais a determinado valor (qualquer numero real). Uma an√°lise b√°sica √© verificar se todos os coeficientes s√£o simultaneamente zero.\n",
    "\n",
    "* H0: $b_{0} = b_{1} = ... = b_{k} = 0$\n",
    "* Ha: ao menos um deles √© diferente de zero.\n",
    "\n",
    "o Teste-F assume:\n",
    "\n",
    "$$ F = \\frac{SQExp / (k-1)}{SQRes /(n-k) }$$\n",
    "\n",
    "Curiosidade, √© poss√≠vel relacionar o teste-F com o R2:\n",
    "\n",
    "$$ F = \\frac{(n-k)}{(k-1)}\\frac{SQExp}{SQRes} = \\frac{(n-k)}{(k-1)}\\frac{SQExp}{(SQTot - SQExp)} = \\frac{(n-k)}{(k-1)}\\frac{(SQExp / SQTot)}{(1- R^{2})} = \\frac{R^{2}/(k-1)}{(1-R^{2})/(n-k)} $$\n",
    "\n",
    "**Interpreta√ß√£o**: A rela√ß√£o entre o teste $F$ e o $R^{2}$ indica que, se o modelo tem um alto $R^{2}$ e um n√∫mero suficiente de vari√°veis independentes (k), ent√£o a rela√ß√£o entre a variabilidade explicada e n√£o explicada √© grande, o que resulta em um valor maior de F e, portanto, maior evid√™ncia contra a hip√≥tese nula. Isso sugere que o modelo √© uma boa representa√ß√£o dos dados e as vari√°veis independentes t√™m um efeito significativo sobre a vari√°vel dependente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplos de Infer√™ncia e Regress√£o no Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "from statsmodels.stats.diagnostic import het_white\n",
    "import statsmodels.formula.api as smf\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "df = pd.read_stata(\"https://github.com/Daniel-Uhr/data/raw/main/cattaneo2.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustando as vari√°veis\n",
    "# Criar a vari√°vel de resultado\n",
    "df['Y'] = df['bweight']\n",
    "# Crie a vari√°vel 'Treated' com valor inicial de 0\n",
    "df['Treated'] = 0\n",
    "# Recodifique 'Treated' para 1 se 'mbsmoke' for igual a 'smoker'\n",
    "df.loc[df['mbsmoke'] == 'smoker', 'Treated'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=-12.830577987447224, pvalue=4.683726413107466e-37)\n"
     ]
    }
   ],
   "source": [
    "# Gerar um teste-t para comparar a m√©dia do peso do beb√™ entre fumantes e n√£o fumantes\n",
    "grupo_fumantes = df[df['Treated'] == 1]['Y']\n",
    "grupo_nao_fumantes = df[df['Treated'] == 0]['Y']\n",
    "# Realizar o teste-t\n",
    "teste_t = ttest_ind(grupo_fumantes, grupo_nao_fumantes)\n",
    "print(teste_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.034\n",
      "Model:                            OLS   Adj. R-squared:                  0.034\n",
      "Method:                 Least Squares   F-statistic:                     164.6\n",
      "Date:                Tue, 06 Aug 2024   Prob (F-statistic):           4.68e-37\n",
      "Time:                        09:27:55   Log-Likelihood:                -36033.\n",
      "No. Observations:                4642   AIC:                         7.207e+04\n",
      "Df Residuals:                    4640   BIC:                         7.208e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept   3412.9116      9.255    368.754      0.000    3394.767    3431.056\n",
      "Treated     -275.2519     21.453    -12.831      0.000    -317.310    -233.194\n",
      "==============================================================================\n",
      "Omnibus:                      739.371   Durbin-Watson:                   2.007\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2256.717\n",
      "Skew:                          -0.824   Prob(JB):                         0.00\n",
      "Kurtosis:                       5.992   Cond. No.                         2.67\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Regress√£o linear\n",
    "reg = smf.ols(\"Y ~ Treated\", data=df).fit()\n",
    "\n",
    "# Imprima os resultados da regress√£o\n",
    "print(reg.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "√â poss√≠vel verificar que o test-t e a regress√£o linear guardam uma rela√ß√£o muito pr√≥xima. Principalmente se considerarmos uma vari√°vel explicativa bin√°ria (Dummy).\n",
    "\n",
    "Vamos adicionar mais covari√°veis na regress√£o e verificar o impacto no teste-t e no teste-F."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.040\n",
      "Model:                            OLS   Adj. R-squared:                  0.039\n",
      "Method:                 Least Squares   F-statistic:                     96.02\n",
      "Date:                Tue, 06 Aug 2024   Prob (F-statistic):           1.38e-41\n",
      "Time:                        09:27:59   Log-Likelihood:                -36020.\n",
      "No. Observations:                4642   AIC:                         7.205e+04\n",
      "Df Residuals:                    4639   BIC:                         7.206e+04\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept   3188.4771     44.559     71.557      0.000    3101.121    3275.833\n",
      "Treated     -252.8434     21.832    -11.581      0.000    -295.645    -210.042\n",
      "medu          17.3578      3.371      5.149      0.000      10.748      23.967\n",
      "==============================================================================\n",
      "Omnibus:                      732.252   Durbin-Watson:                   2.014\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2208.079\n",
      "Skew:                          -0.820   Prob(JB):                         0.00\n",
      "Kurtosis:                       5.954   Cond. No.                         70.5\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Regress√£o linear 2\n",
    "reg2 = smf.ols(\"Y ~ Treated + medu\", data=df).fit()\n",
    "\n",
    "# Imprima os resultados da regress√£o\n",
    "print(reg2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repare que o R2 e R2 ajustado aumentam levemente com a inclus√£o de mais vari√°veis explicativas. Isso significa que o poder explicativo do modelo aumenta. A Estat√≠stica do teste-F reduziu, entretanto permanece significativa, indicando que as covari√°veis conjuntamente s√£o significativas.\n",
    "* OBS: A estat√≠stica F avalia a signific√¢ncia global do modelo em compara√ß√£o com um modelo \"vazio\", enquanto a estat√≠stica Omnibus testa a signific√¢ncia global do modelo considerando a distribui√ß√£o dos res√≠duos."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
